{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bronze-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from boundariesdetectioncnn.train import train_model\n",
    "from boundariesdetectioncnn import configs \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sophisticated-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boundariesdetectioncnn.data import dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "excess-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def load_weights(input, name, epochs):\n",
    "    \n",
    "    if input not in configs.INPUTS.keys():\n",
    "        raise ValueError('Select a proper input name')\n",
    "        \n",
    "    if name == 'mel':\n",
    "        subdir = name\n",
    "    elif name == 'sslm':\n",
    "        subdir = name + '/' + input\n",
    "    elif name == 'mel_sslm_combined':\n",
    "        subdir = name + '/' + input + input2\n",
    "    elif name == 'mel_2sslm_combined':\n",
    "        subdir = name + '/' + input + input2\n",
    "    elif name == 'mel_4sslm_combined':\n",
    "        subdir = name + '/' + input + input2 + input3 + input4\n",
    "            \n",
    "    # load model\n",
    "    model = configs.load_model(name)\n",
    "    \n",
    "    # load pretrained weights\n",
    "    weights_path = os.path.join(\"../pretrained_weights/\" + subdir, \"saved_model_\" + str(epochs) + \"epochs.bin\")\n",
    "    if not os.path.exists(weights_path):\n",
    "        raise ValueError('Pretrained weights for the selected epochs does not exist.')\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(weights_path))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "owned-shakespeare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Fusion(\n",
       "  (cnn1): CNN_1(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(5, 7), stride=(1, 1), padding=(2, 3))\n",
       "    (pool1): MaxPool2d(kernel_size=(5, 3), stride=(5, 1), padding=(1, 1), dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (cnn2): CNN_2(\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1), padding=(1, 6), dilation=(1, 3))\n",
       "    (dropout1): Dropout2d(p=0.5, inplace=False)\n",
       "    (lineal1): Conv1d(1024, 128, kernel_size=(1,), stride=(1,))\n",
       "    (dropout2): Dropout2d(p=0.5, inplace=False)\n",
       "    (lineal2): Conv1d(128, 1, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights(input='mel', name='mel', epochs=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "educated-chest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pretrained_weights/mel\\saved_model_180epochs.bin\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2ac5e57bb404>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mpredict_song_testdataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msong_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-2ac5e57bb404>\u001b[0m in \u001b[0;36mpredict_song_testdataset\u001b[1;34m(input, name, epochs, song_id, input2, input3, input4)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pretrained weights for the selected epochs does not exist.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def predict_song_testdataset(input, name, epochs, song_id, input2='', input3='', input4=''):\n",
    "    \n",
    "    if input not in configs.INPUTS.keys():\n",
    "        raise ValueError('Select a proper input name')\n",
    "    \n",
    "    #build test dataloaders\n",
    "    dataset, data_loader = dataloaders.build_dataloader(batch_size=configs.ParamsConfig.BATCH_SIZE, input=input, run='test')\n",
    "        \n",
    "    # load model\n",
    "    model = configs.load_model(name)\n",
    "    \n",
    "    if name == 'mel':\n",
    "        subdir = name\n",
    "    elif name == 'sslm':\n",
    "        subdir = name + '/' + input\n",
    "    elif name == 'mel_sslm_combined':\n",
    "        subdir = name + '/' + input + input2\n",
    "    elif name == 'mel_2sslm_combined':\n",
    "        subdir = name + '/' + input + input2\n",
    "    elif name == 'mel_4sslm_combined':\n",
    "        subdir = name + '/' + input + input2 + input3 + input4\n",
    "            \n",
    "    # load model\n",
    "    model = configs.load_model(name)\n",
    "    \n",
    "    # load pretrained weights\n",
    "    weights_path = os.path.join(\"../pretrained_weights/\" + subdir, \"saved_model_\" + str(epochs) + \"epochs.bin\")\n",
    "    print(weights_path)\n",
    "    if not os.path.exists(weights_path):\n",
    "        raise ValueError('Pretrained weights for the selected epochs does not exist.')\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(weights_path))\n",
    "        model.eval()\n",
    "\n",
    "predict_song_testdataset(input='mel', name='mel', epochs=180, song_id=3, input2=None, input3=None, input4=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "retained-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import plot\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import mir_eval\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "prerequisite-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_song_testdataset(input, name, epochs, song_id, input2=None, input3=None, input4=None):\n",
    "    \n",
    "    if input not in configs.INPUTS.keys():\n",
    "        raise ValueError('Select a proper input name')\n",
    "    \n",
    "    #build test dataloaders\n",
    "    dataset, data_loader = dataloaders.build_dataloader(batch_size=configs.ParamsConfig.BATCH_SIZE, input=input, run='test')\n",
    "        \n",
    "    # load model\n",
    "    model = load_weights(input, name, epochs)\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    mel = np.expand_dims(mels_dataset[song_id][0], 0)\n",
    "    mel = torch.Tensor(mel)\n",
    "    pred = model(torch.Tensor(mls))\n",
    "    pred = pred.view(-1,1)\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred_new = pred.detach().numpy()\n",
    "    pred_new = pred_new[:,0]\n",
    "\n",
    "    #------------------------------------------------------------------------------\n",
    "    label = dataset[song_id][2]\n",
    "    label = label[1:]\n",
    "    reference = np.array((np.copy(label[:-1]), np.copy(label[1:]))).T\n",
    "\n",
    "    peak_position = signal.find_peaks(pred_new, height=delta, distance=lamda)[0] #array of peaks\n",
    "    peaks_position = ((peak_position-configs.ParamsConfig.PADDING_FACTOR)*configs.ParamsConfig.POOLING_FACTOR*configs.ParamsConfig.HOP_LENGHT)/configs.ParamsConfig.SAMPLING_RATE\n",
    "    for i in range(len(peaks_position)):\n",
    "        if peaks_position[i] < 0:\n",
    "            peaks_position[i] = 0\n",
    "\n",
    "    pred_positions = np.array((np.copy(peaks_position[:-1]), np.copy(peaks_position[1:]))).T\n",
    "    repeated_list = []\n",
    "    for j in range(pred_positions.shape[0]):\n",
    "            if pred_positions[j,0] == pred_positions[j,1]:\n",
    "                repeated_list.append(j)\n",
    "    pred_positions = np.delete(pred_positions, repeated_list, 0)\n",
    "\n",
    "\n",
    "    P, R, F, TP = mir_eval.segment.detection(reference, pred_positions, window=configs.ParamsConfig.WINDOW, beta=beta, trim=False)\n",
    "    print(\"Threshold\", delta)\n",
    "    print('P =',P,'R =',R,'F =',F)\n",
    "\n",
    "    TP = len(TP)\n",
    "    FP = ((1 - P)*TP) / P\n",
    "    FN = ((1 - R)*TP) / R\n",
    "\n",
    "    print(\"True Positives:\", TP)\n",
    "    print(\"False Positives:\", FP)\n",
    "    print(\"False Negatives:\", FN)\n",
    "\n",
    "    delta_array = np.zeros_like(sslms_dataset[song_id][1])\n",
    "    vector = np.arange(sslms_dataset[song_id][0].shape[2])\n",
    "    #------------------------------------------------------------------------------\n",
    "    #Plot out vs labels\n",
    "    for i in range(len(delta_array)):\n",
    "        delta_array[i] = delta\n",
    "    plt.plot(vector, delta_array*300, color='aqua')\n",
    "    plt.plot(vector, dataset[song_id][1]*300, 'r-', label='Labels')\n",
    "    plt.plot(vector, pred[:,0].detach().numpy()*300, 'w-', label='Output')\n",
    "    plt.imshow(dataset[song_id][0][0,...], origin = 'lower', aspect=1)\n",
    "    plt.ylabel(\"lag bins\")\n",
    "    matplotlib.rcParams.update({'font.size': 10})\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #------------------------------------------------------------------------------\n",
    "    #Plot out vs labels\n",
    "    for i in range(len(delta_array)):\n",
    "        delta_array[i] = delta\n",
    "    \n",
    "    trace1 = go.Scatter(x = vector,\n",
    "                        y = sslms_dataset[song_id][1],\n",
    "                        mode = 'lines',\n",
    "                        name = 'labels',\n",
    "                        marker = dict(color = 'rgba(72, 141, 244, 1)') #blue\n",
    "                        )\n",
    "    trace2 = go.Scatter(x = vector,\n",
    "                        y = pred_new,\n",
    "                        mode = 'lines',\n",
    "                        name = 'predictions',\n",
    "                        marker = dict(color = 'rgba(15, 194, 129, 1)') #green\n",
    "                        )\n",
    "    trace3 = go.Scatter(x = vector,\n",
    "                        y = delta_array,\n",
    "                        mode = 'lines',\n",
    "                        name = 'delta',\n",
    "                        marker = dict(color = 'rgba(229, 183, 31, 1)') #yellow\n",
    "                        )\n",
    "    trace4 = go.Scatter(x = peak_position,\n",
    "                        y = [pred_new[j] for j in peak_position],\n",
    "                        mode = 'markers',\n",
    "                        name = 'estimated peaks',\n",
    "                        marker = dict(color = 'rgba(240, 87, 57, 1)') #red\n",
    "                        )\n",
    "    data = [trace1, trace2, trace3, trace4]\n",
    "    layout = dict(title = 'Song' + song_id + 'SALAMI 2.0  ' + epochs + ' epochs',\n",
    "                  xaxis= dict(title= 'Time (seconds)',ticklen= 5,zeroline= False))\n",
    "    fig = dict(data = data, layout = layout)\n",
    "    plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "interracial-wisconsin",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mels_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-b4b566f6e8da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict_song_testdataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msong_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-abeef16e0d0f>\u001b[0m in \u001b[0;36mpredict_song_testdataset\u001b[1;34m(input, name, epochs, song_id, input2, input3, input4)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mmel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmels_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msong_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mmel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mels_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "predict_song_testdataset(input='mel', name='mel', epochs=180, song_id=3, input2=None, input3=None, input4=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-diploma",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
